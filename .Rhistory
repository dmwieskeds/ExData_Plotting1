skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
mad_libs(place = "the circus", adjective = "smelly", noun = "water fountain")
submit
submit()
submit()
"I" "%p%" "love" "%P%" "R!"
"%p%"("I", "love", "R!")
submit()
submit()
"%p%"("I", "love", "R!")
"I" "%p%" "love" "%P%" "R!"
'I' "%p%" 'love' "%P%" 'R!'
"%p%"("I", "love", "R!")
"%p%"("I", "love")
'I' "%p%" 'love' "%P%" 'R!'
'I' %p% 'love' %P% 'R!'
"I" %p% "love" %P% "R!"
sumbmit()
submit()
"I" %p% "love" %P% "R!"
submit()
info()
"I" %p% "love" %P% "R!"
'I' %p% 'love' %P% 'R!'
"I" %p% "love" %p% "R!"
main()
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
t1 <- Sys.time()
t1
class(t1)
unclass(t1)
t2 <- as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quarter(t2)
quarters(t2)
t3 <- "October 17, 1986 08:24"
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
getwd()
getws()
getwd()
getwd()
setwd("datasciencecoursera"
)
setwd("C:/Users/dawn_w/Documents/datasciencecoursera")
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(x:size))
select(cran, -(date:size))
select(cran, -(x:size))
select(cran, -("x":size))
rlang::last_error()
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
swirl()
summarize(cran, avg_bytes = mean(size))
0
load("~/DataScienceCoursera/Course3-GettingAndCleaningData/Quiz1,ex5.RData")
housing
load("~/DataScienceCoursera/Course3-GettingAndCleaningData/Quiz1,ex5.RData")
load("~/DataScienceCoursera/Course3-GettingAndCleaningData/.RData")
load("~/DataScienceCoursera/Course3-GettingAndCleaningData/Quiz1,ex5.RData")
DT
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT$pwgtp15,by=DT$SEX)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
DT[,mean(pwgtp15),by=SEX]
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
tapply(DT$pwgtp15,DT$SEX,mean)
?data.table
??data.table
load("~/DataScienceCoursera/Course3-GettingAndCleaningData/Quiz1,ex5.RData")
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(x:size))
select(cran, -(X:size))
filter(cran, package=="swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
in.na(c(3, 5, NA, 10))
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran, country, desc(r_version), ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, c("sex", "class"))
submit()
students3
?gather
submit()
?spread
submit()
submit()
submit()
rlang::last_error(
)
submit()
submit()
submit()
submit()
library(readr)
parse_number("class5")
submit()
students4
submit()
?unique
submit()
submit()
passed
failed
mutate(passed, status = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
bind_rows(passed, failed)
sat
?contains
?select
?gather
submit()
?select
submit()
submit()
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url, "zipfile.zip")
## read in data tables
library(data.table)
traindata <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/X_train.txt"))
testdata <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/X_test.txt"))
trainActivity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/y_train.txt"))
testActivity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/y_test.txt"))
Activity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/activity_labels.txt"))
trainSubject <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/subject_train.txt"))
testSubject <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/subject_test.txt"))
labels <- read.table(unz("zipfile.zip", "UCI HAR Dataset/features.txt"))
unlink("zipfile.zip")
## use features.txt file to add descriptive column headers to each data set
names(traindata) <- labels[,2]
names(testdata) <- labels[,2]
## add Activity column to each data set (do before combining)
trainActivityLabels <- trainActivity
trainActivityLabels$V2 <- Activity$V2[match(trainActivityLabels$V1,Activity$V1)]
traindata2 <- cbind(trainActivityLabels[,2],traindata)
testActivityLabels <- testActivity
testActivityLabels$V2 <- Activity$V2[match(testActivityLabels$V1,Activity$V1)]
testdata2 <- cbind(testActivityLabels[,2],testdata)
## add Subject column to each data set and rename column (do before combining)
traindata3 <- cbind(trainSubject,traindata2)
names(traindata3)[1] <- "Subject"
names(traindata3)[2] <- "Activity"
testdata3 <- cbind(testSubject,testdata2)
names(testdata3)[1] <- "Subject"
names(testdata3)[2] <- "Activity"
## combine train and test data sets
combinedData <- rbind(traindata3,testdata3)
## extract only measurements on the mean and stanard deviation for each measurement
extractData <- combinedData[,grep(("Subject|Activity|mean()|std()"),names(combinedData))]
extractData
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url, "zipfile.zip")
## read in data tables
library(data.table)
traindata <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/X_train.txt"))
testdata <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/X_test.txt"))
trainActivity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/y_train.txt"))
testActivity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/y_test.txt"))
Activity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/activity_labels.txt"))
trainSubject <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/subject_train.txt"))
testSubject <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/subject_test.txt"))
labels <- read.table(unz("zipfile.zip", "UCI HAR Dataset/features.txt"))
unlink("zipfile.zip")
## use features.txt file to add descriptive column headers to each data set
names(traindata) <- labels[,2]
names(testdata) <- labels[,2]
## add Activity column to each data set (do before combining)
trainActivityLabels <- trainActivity
trainActivityLabels$V2 <- Activity$V2[match(trainActivityLabels$V1,Activity$V1)]
traindata <- cbind(trainActivityLabels[,2],traindata)
testActivityLabels <- testActivity
testActivityLabels$V2 <- Activity$V2[match(testActivityLabels$V1,Activity$V1)]
testdata <- cbind(testActivityLabels[,2],testdata)
## add Subject column to each data set and rename column (do before combining)
traindata <- cbind(trainSubject,traindata)
names(traindata)[1] <- "Subject"
names(traindata)[2] <- "Activity"
testdata <- cbind(testSubject,testdata)
names(testdata)[1] <- "Subject"
names(testdata)[2] <- "Activity"
## combine train and test data sets
combinedData <- rbind(traindata,testdata)
## extract only measurements on the mean and stanard deviation for each measurement
extractData <- combinedData[,grep(("Subject|Activity|mean()|std()"),names(combinedData))]
extractData
## download data from url provided in assignment
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url, "zipfile.zip")
## read necessary data tables into R
library(data.table)
traindata <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/X_train.txt"))
testdata <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/X_test.txt"))
trainActivity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/y_train.txt"))
testActivity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/y_test.txt"))
Activity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/activity_labels.txt"))
trainSubject <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/subject_train.txt"))
testSubject <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/subject_test.txt"))
labels <- read.table(unz("zipfile.zip", "UCI HAR Dataset/features.txt"))
## remove zip file; no longer needed
unlink("zipfile.zip")
## use features.txt file to add descriptive column headers to each data set
names(traindata) <- labels[,2]
names(testdata) <- labels[,2]
## add Activity column to each data set (do before combining)
trainActivityLabels <- trainActivity
trainActivityLabels$V2 <- Activity$V2[match(trainActivityLabels$V1,Activity$V1)]
traindata <- cbind(trainActivityLabels[,2],traindata)
testActivityLabels <- testActivity
testActivityLabels$V2 <- Activity$V2[match(testActivityLabels$V1,Activity$V1)]
testdata <- cbind(testActivityLabels[,2],testdata)
## add Subject column to each data set and rename column (do before combining)
traindata <- cbind(trainSubject,traindata)
names(traindata)[1] <- "Subject"
names(traindata)[2] <- "Activity"
testdata <- cbind(testSubject,testdata)
names(testdata)[1] <- "Subject"
names(testdata)[2] <- "Activity"
## combine train and test data sets
combinedData <- rbind(traindata,testdata)
## extract only measurements on the mean and stanard deviation for each measurement
extractData <- combinedData[,grep(("Subject|Activity|mean()|std()"),names(combinedData))]
install.packages("dplyr")
library(dplyr)
extractData %>% group_by(Subject, Activity) %>% summarize_each(funs(mean))
##########################################################################################
######################### Getting and Cleaning Data Project ##############################
##########################################################################################
library(dplyr)
library(data.table)
####### NAMES DATASETS ########
feature.names <- read.table("Project/UCI HAR Dataset/features.txt",header=FALSE,
sep="",dec=".")
activity.names <- read.table("Project/UCI HAR Dataset/activity_labels.txt",header = FALSE,
sep="",dec=".")
####### TRAINING DATASET ########
# Importing data
train.data <- read.table("Project/UCI HAR Dataset/train/X_train.txt",header=FALSE,
sep = "",dec=".")
train.subject<- read.table("Project/UCI HAR Dataset/train/subject_train.txt",header=FALSE,
sep="",dec=".")
## download data from url provided in assignment
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url, "zipfile.zip")
## read necessary data tables into R
library(data.table)
x_train <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/X_train.txt"))
x_test <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/X_test.txt"))
y_train <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/y_train.txt"))
y_test <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/y_test.txt"))
##Activity <- read.table(unz("zipfile.zip", "UCI HAR Dataset/activity_labels.txt"))
subject_train <- read.table(unz("zipfile.zip", "UCI HAR Dataset/train/subject_train.txt"))
subject_test <- read.table(unz("zipfile.zip", "UCI HAR Dataset/test/subject_test.txt"))
## remove zip file; no longer needed
unlink("zipfile.zip")
X <- rbind(x_train, x_test)
Y <- rbind(y_train, y_test)
Subject <- rbind(subject_train, subject_test)
Merged_Data <- cbind(Subject, Y, X)
TidyData <- Merged_Data %>% select(subject, code, contains("mean"), contains("std"))
TidyData$code <- activities[TidyData$code, 2]
## download data from url provided in assignment
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url, "zipfile.zip")
activities <- read.table(unz("zipfile.zip", "UCI HAR Dataset/activity_labels.txt"))
## remove zip file; no longer needed
unlink("zipfile.zip")
TidyData$code <- activities[TidyData$code, 2]
TidyData <- Merged_Data %>% select(subject, code, contains("mean"), contains("std"))
X <- rbind(x_train, x_test)
Y <- rbind(y_train, y_test)
Subject <- rbind(subject_train, subject_test)
Merged_Data <- cbind(Subject, Y, X)
TidyData <- Merged_Data %>% select(subject, code, contains("mean"), contains("std"))
Merged_Data <- cbind(Subject, Y, X)
Merged_Data
## remove zip file; no longer needed
unlink("zipfile.zip")
install.packages("swirl")
library(swirl)
swirl()
install_from_swirl("Exploratory Data Analysis")
swirl()
install.packages("swirl")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
swirl()
head(pollution)
dim(pollution)
summary(pollution$pm25)
quantile(ppm)
boxplot(ppm, col = "blue")
abline(h = 12)
hist(ppm, col = "green")
rug(ppm)
low
high
hist(ppm, col =
"green", breaks = 100)
rug(ppm)
hist(ppm, col = "green")
abline(v = 12, lwd = 2)
abline(v = median(ppm), col =
"magenta", lwd = 4)
names(pollution)
reg <- table(pollution$region)
reg
barplot(reg, col = "wheat", main = "Number of Counties in Each Region")
install.packages("swirl")
library(swirl)
install_from_swirl("Exploratory
Data Analysis")
install_from_swirl("Exploratory Data Analysis")
swirl()
head(pollution)
dim(pollution)
summary(pollution$pm25)
install.packages("swirl")
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
head(pollution)
dim(pollution)
summary(pollution$pm25)
quantile(ppm)
boxplot(ppm)
boxplot(ppm,col = "blue")
abline(h = 12)
hist(ppm,col = "green")
rug(ppm)
low
high
hist(ppm,col = "green", breaks = 100)
rug(ppm)
hist(ppm,col = "green")
abline(v = 12,lwd = 2)
abline(v = median(ppm), col = "magenta", lwd = 4)
names(pollution)
reg <- table(polltion$region)
reg <- table(pollution$region)
reg
barplot(reg, col = "wheat", main = "Number of Counties in Each Region")
boxplot(pm25~region,data = pollution,col = "red")
par(mfrow=c(2,1),mar=c(4,4,2,1))
east <- subest(pollution,region=="east")
east <- subset(pollution,region=="east")
head(east)
hist(east$pm25,col = "green")
hist(subset(pollution,region=="west")$pm25,col = "green")
with(pollution, plot(latitude,pm25))
abline(h = 12,lwd = 2,lty = 2)
plot(pollution$latitude, ppm, col = pollution$region)
abline(h = 12,lwd = 2,lty = 2)
par(mfrow = c(1,2), mar = c(5,4,2,1))
west <- subset(pollution, region == "west")
plot(west$latitude, west$pm25, main = "West")
plot(east$latitude, east$pm25, main = "East")
library("plot1.R")
load("plot1.R")
install.packages("plot1.R")
getwd()
setwd("C:/Users/dawn_w/Documents/DataScienceCoursera/Course4-ExploratoryDataAnalysis/gitbash/ExDAta_Plotting1"
)
ls
dir()
install.packages("plot1.R")
load("
plot1.R")
library(plot1.R)
install.packages("plot1.R")
dev.off()
